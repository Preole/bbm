November 18^^th^^, 2013
=======================

I have completed the Lexer of the new compiler, and I'm now thoroughly 
testing the parser with a complete EBNF grammar. As I'm testing the 
parser, I find that my code parser keeps on bloating until it is not so 
readable anymore. I also keep encountering test cases that forces me to 
make design decisions, including attempts at abusing the parser.

I should outline the challenges facing the parser right now, as 
well as things it did well with.

; Challenges

  : Syntax abuse
  : Code smell
  : Italic
  : Syntax escaping
  : End of Line (EOL) and Invisible Whitespace
  : Fenced Block Force Indent
  
; Kudos

  : Aesthetics
  : Simplicity
  : Power & Versatility



Challenges
==========
  
Syntax abuse
------------

There are a few ways a writer can abuse the parser and make it crash, divided 
into the following categories:

; Performance

  : This is by far the most painful attack against the compiler, due to its 
    error recovery strategy. When the parser encounters contexts where the 
    text must be parsed literally in a paragraph, it must backtrack to the 
    starting symbol upon failure. For example, if the parser tries to parse 
    a URL and it doesn't see a closing angle bracket, it will backtrack to 
    the opening angle bracket that started the URL context.
    
    The backtracking error recovery strategy is useful for preventing error 
    propagation; That is, if the writer made an error making a hyperlink, 
    the hyperlink doesn't end up destroying the rest of the text. Instead, 
    the starting symbol is treated as normal text, and the rest of the 
    markup will be parsed as normal.
    
    This error recovery strategy, however, has time complexity of O(N^^2^^), 
    because it is backtracking naively, parsing for URL again and again even 
    though there's no ending token in that paragraph. Here's the culprit code:
    
    """
    ?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<
    ?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<
    ?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<?<
    **The rest of the paragraph**
    """
    
    There are 54 open external link symbols in the example paragraph, and 
    there's no closing angle bracket to close any of them. The first link 
    must parse the entire paragraph, while the second must parse the entire 
    paragraph minus the first symbol, and the third the same except the first 
    two symbols, and so on. Below is the number of symbols the parser needs
    to grind through on that paragraph.
    
    """
    54 + 53 + 52 + ... + 1.
    """
    
    Approximately ~100 of these symbols are enough to introduce a barely 
    noticeable delay, while ~1000 of these symbols will cause a two-second 
    delay on a low-end PC laptop. This is not acceptable if this parser is 
    to be used on a public platform, such as a forum or a commenting system.
    
    The easiest answer would be providing no error recovery, and delegate 
    the responsibility to the writer. The output should be mangled so much, 
    it would be difficult to miss the problem section, which leads to faster 
    error correction on the writer's behalf.
    
    On the other hand, I would like to handle the failure gracefully. For 
    URLs, it's easy to do with a flag; If the verbatim section didn't see a 
    closing token, I can tell the parser to never look for URLs again. 
    Sadly, this doesn't quite work with the internal link syntax, which 
    uses square brackets with bracket balancing mechanism. Here's the code 
    that can make a fool out of my solution:
    
    """
    #[#[#[#[My-Internal-ID]-SomeOtherNumber] 
    """
    
    There are six opening internal links and two closing square brackets. 
    If I merely flagged the parser to never look for URLs again, the valid 
    internal link (the second-to-last) won't get recognized after the 
    first URL has failed, which is referring to the following ID:
    
    """
    #[My-Internal-ID]-SomeOtherNumber
    """
    
    The same problem exists for inline code snippets, as whether they open 
    or close depend on whether the number of "@", or at signs match in the 
    paragraph. In this code snippet, the fourth one has a match, which will 
    not get recognized if I simply set the flag after the first failure.
    
    """
    """ """ """ """ """ """
    """
    
    Here's the abusive right-triangle equivalent in Markdown, which has the 
    same dilemma for error recovery when inline code snippets don't match.
    
    """
    `
    ``
    ```
    ````
    `````
    ``````
    ```````
    ````````
    `````````
    ``````````
    ```````````
    ````````````
    `````````````
    ``````````````
    ```````````````
    ````````````````
    `````````````````
    ``````````````````
    ```````````````````
    """
    
    And here's the (in)-consistent output, which is to be expected since 
    it's a pathological input case.
    
    - """
      <p>` ``</p>
      <pre><code>````
      </code></pre>

      <p>``</p>
      <pre><code class="```">```````
      </code></pre>

      <p>`````</p>
      <pre><code class="``````">``````````
      </code></pre>

      <p>````````</p>
      <pre><code class="`````````">`````````````
      </code></pre>

      <p>```````````</p>
      <pre><code class="````````````">````````````````
      </code></pre>

      <p>``````````````</p>
      <pre><code class="```````````````">```````````````````
      </code></pre>

      <p>`````````````````</p>
      <pre><code class="``````````````````">``````````````````````
      </code></pre>

      <p>```````````````````` ```````````````````````` `````````````````````````</p>
      """
    
    - """
      <p>` ``</p>
      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <pre><code>`</code></pre>

      <p>`````````````````````````</p>
      """
    
    - """
      <p>` `` ``` ```` ````` `````` ``````` ```````` ````````` `````````` ```````````
      ```````````` ````````````` `````````````` ``````````````` ````````````````
      ````````````````` `````````````````` ``````````````````` ````````````````````
      ````````````````````` `````````````````````` ``````````````````````` ````````````````````````
      `````````````````````````</p>
      """
    
    I suppose I can deal with it by counting. That is, the parser must see
    X more opening symbols before it's willing to parse in verbatim context
    again.
    
    In any case, error recovery behavior makes the parser needlessly 
    complicated.

; Structure

  : The other kind of syntax abuse involves mangling the structure. In this 
    particular markup language, the user can nest bullet lists, tables and 
    block quote ad nauseum even on the same line. Here's a code snippet for 
    demonstration.
    
    """
    - 1. + 2. 3. * 4. * * * * * > This is an example of nesting abuse.
    """
    
    It's a bullet list containing a numbered list containing a bullet list, 
    and so on. With this much list nesting, the document structure is going 
    to have a very huge left-margin. This does not bode well for 
    accessibility of the output, and the semantic suffers as well.
    
    Disabling this syntax prevents legitimate use of this structure, like 
    the following code snippet:
    
    """
    > - This person's blockquote is a bullet list
      - This is his second point.
      - This is his other quote, which contains another block quote.
      
        Joe said:
      
        > This is a very insightful comment by Joe.
        
          This is Joe's second paragraph
          
          Joe quoted from Smith:
          
          > Smith said this very sentence.
      
      This paragraph is not part of the deeply nested block quote inside 
      the bullet list's last item.
      
    > This is a new blockquote separate from the previous one, as 
      demonstrated by indentation.
    """
    
    The current workaround is to set an upper limit for these kinds of 
    structures. Once the upper limit is being breached, the parser falls 
    back to parsing paragraphs.



Code Smell
----------
    
Right now, the Lexer's code base is perfectly okay, so is the block grammar 
portion of the parser. Once I get to the inline grammar, it's a big mess. 
The paragraph simply has too many things it needs to look out for, for 
every lexical token inside the paragraph. 

In short, the inline grammar of my parser is not readable without the 
comment I've written, which is a lot. I want to have the code explain 
themselves to me, instead of doing pointer comparison and all the 
program-specific stuff.

"""
function parsePara(startCol, formatStack, bracketStack, disallowLink)
{//Paragraph
 var minCol = (startCol || currToken.col);
 var paraNode = new ASTNode(AST_ENUM.PARA);
 var childNode = null;
 var fmtStack = formatStack ? formatStack : [];
 var textSoFar = [];
 var symbolPos = currPos;
 var symbol = currToken;
 var rawText = null;
 
 while (!LA_isParaEnd(minCol))
 {    
  if (symbol.isInTypeMap(LEX_AST_FMT_MAP))
  {//Text formatting.
   childNode = parseFMT(minCol, 
   fmtStack, bracketStack, disallowLink, paraNode);
  }
  else if (symbol.isType(LEX_ENUM.LINK_IMG)) 
  {//Images
   childNode = parseLink(minCol);
  }
  else if (symbol.isInTypeMap(LEX_AST_LINK_MAP) && !disallowLink) 
  {//Links, if allowed. (Disallowed for link display text)
   childNode = parseLink(minCol);
  }
  else if (symbol.isType(LEX_ENUM.CODE)) 
  {//Inline code
   rawText = parseVerbatim(minCol);
   if (rawText)
   {
    childNode = new ASTNode(AST_ENUM.CODE);
    childNode.addChildText(rawText);
   }
  }
  else if (parseBracket(bracketStack) || LA_isSetext(minCol)) 
  {//Bracket Matching or SeTexT header
   shift(); //Skip the closing token, collect text and return.
   break;
  }
  
  if (!(childNode instanceof ASTNode))
  { //Not a significant token in paragraph, or link/code with errors.
   var ws_len = currToken.getLength();
   if (LA_isLeadWS() && ws_len >= minCol - 1)
   {
    if (ws_len > minCol - 1)
    {
     textSoFar.push(currToken.substring(minCol - 1, ws_len));
    }
   }
   else
   {
    shiftTo(symbolPos);
    textSoFar.push(symbol.lexeme);
   }
  }
  else if (childNode === paraNode)
  { //Balanced text-formatting tokens.
   break;
  }
  else if (childNode.isType(AST_ENUM.PARA))
  { //Unbalanced text-formatting tokens.
   textSoFar.push(symbol.lexeme);
   paraNode.addChildText(textSoFar.join(""));
   paraNode.addChildren(childNode);
   textSoFar = [];
  }
  else
  { //Code, link, and any other cases.
   paraNode.addChildText(textSoFar.join(""));
   paraNode.addChild(childNode);
   textSoFar = [];
  }
  
  if (currPos === symbolPos)
  {
   shift();
  }
  
  symbolPos = currPos;
  symbol = currToken;
  childNode = null;
  rawText = null;
 }
 
 if (!formatStack) //Root paragraph. Check for SeText presence.
 {
  if (symbol.isType(LEX_ENUM.ATX_END) || symbol.isType(LEX_ENUM.DIV_LINE))
  {
   paraNode.type = AST_ENUM.HEADER;
   paraNode.metaData.HEADERLVL = symbol.isType(LEX_ENUM.ATX_END) ? 1 : 2;
   shift();
  }
 }
 
 paraNode.addChildText(textSoFar.join(""));
 paraNode.addChild(childNode);
 return paraNode;
}
"""

Not pretty. It's 100 lines of code totalling 2639 bytes without any 
indentation. That's just the decision tree of a paragraph. If I were to 
add in the hyperlink syntax and other things, it totals up to 7KB of code. 
I thought that paragraphs are supposed to be simpler than these monolithic 
functions. I haven't included supporting functions that exist solely for 
the purpose helping a paragraph.

The other code smell is trimming lead whitespace. The same code snippet was 
used repeatedly in different parts of the parser, as listed below:

  - Code block.
  - Paragraph, verbatim mode.
  - Paragraph, standard mode.
  - Aside block

This work should be centralized into one function, rather than repeated all 
over the place. 

It seems like my hand-written parser is far from human-readable.



Italics
-------
 
As of November 18^^th^^, 2013, BakaBakaMark Version 2 is using two 
consecutive typewriter's single quote for the Italic typeface syntax. 
"""''""" While that syntax has excellent aesthetics on a monospaced font 
and is easy to recognize, it has severe conflict with the English grammar. 
Typewriter's single quote doesn't sit well with the English single quotation 
mark and apostrophe from a typist's perspective; Specifically, they all use 
the same character on a typical QWERTY keyboard. 
 
It's imperative that I find a replacement for this particular syntax as 
soon as possible, considering that these symbols are very often used in 
a typesetting context. I have a few symbols left from the following list: 
 
- """*""" Single asterisk, like Markdown. 
- """//""" Two forward slashes, like WikiCreole. 
 
Markdown's single asterisk is a quick way to solve the issue, but the 
syntax is by far too fragile. It also prevents the writer from using 
asterisks literally, which has use cases different from indicating 
emphasis. 
 
Double forward slashes are resilient, at the cost of visual noise. 
Simply put, they don't look pretty, but they get the job done and 
they are easy to parse. Very rarely does a writer need to use two 
forward slashes at once, and very rarely will the writer need to 
Italicize the forward slash character itself, unless the writer is 
talking about a file path in a computer system. In such use cases, 
the writer should use an inline code section to wrap the text. 
 
I'm not happy with either solution.
 
It appears I've run out of elegant markup symbols. I will have to 
settle with """''""" for the time being, or **introduce a character 
escape into the grammar.** It's not like forgetting to give apostrophe 
italic format is a big deal, and there's always literal asterisks at 
the ready as a substitute. 



Syntax Escaping
---------------

Syntax escaping has always been one of my headaches in designing this 
language. It's a tool, a means to an end, instead of a goal. It's an ugly 
tool that salvages design failure when absolutely necessary. I personally 
think if my writers have to use this syntax, my design has already failed. 
Here's my philosophy to designing and engineering, coming from a certain 
Panda:

> The secret ingredient is... nothing!

  -- Mr. Ping, __Kung-Fu Panda__

Following that logic, I should build my design such that my writer won't 
really *need* syntax escaping. My impulse is to simply eliminate syntax 
escaping altogether, since it makes my life and everyone else's life
easier. Yet, minimalist design philosophy like this is dangerous.

This philosophy is similar to removing braking systems from the cars we drive. 
I'm vehemently against this design principle, because often times, tools and 
utility outweigh aesthetics and grace. If lives are at stake when car brakes 
fail and cars go crashing, then lives are at stake when the reader 
mis-interprets a document due to typesetting errors, or when the writer 
can't write in a certain way.

Therefore, syntax escaping should not be omitted.

However, I'm stuck on the way syntax escaping should operate. I need to 
answer at least these questions:

- Lexical construct: How will it look like?
- Syntax rules: How does it work? 

For lexical construct, it's probably a single backslash character, which is 
the conventional escape character in many different programming languages, 
like Python. It also has the least number of conflict with the English 
grammar; In fact, I don't know any written or spoken language where its 
grammar uses the ASCII backslash character.

The syntax rule is the difficult one, because the language's context has 
different opinions:

1. The first backslash is always discarded, and the next character is a plain 
   text token. This premise holds true in all contexts, including verbatim 
   text sections. Programming languages tend to handle String literals in 
   this manner.

   - This approach is unambiguous and simple, which means it's easy to 
     implement and there's little room for errors.
     
   - The downside is that, if there's a verbatim text section, and the text 
     contains backslashes (such as computer code), these backslashes are lost 
     when they're rendered in the output, unless the writer adds another 
     backslash character right before it.
    
2. The backslash character is a lexical token (escape). The next token is 
   demoted to a text token, or processed differently depending on the context.
   
   The escape token is preserved and outputted during verbatim sections of 
   the text, such as a URL. In other contexts, the escape token is discarded, 
   and the next token turns into a TEXT token.
   
   This method has one big problem with inline code snippets and URL 
   delimiters. When the delimiter token is escaped, it's not clear 
   whether the backslash token should be treated literally, or if it 
   should be discarded.
   
   """
   <?My URL With backslash. \\> My URL continues>
   
   """class \\""" Dog"""
   """
   
   Markdown's (partial) answer is to escape only certain characters. If I 
   didn't read its spec and simply assumed the first point, (Because most 
   people, like myself, won't read too deeply) I would put in something like 
   this:
   
   """
   ``Bad \\`` Bad``
   """
   
   Thinking that I have escaped the first delimiter successfully, I then
   get this (un)expected result:
   
   """
   <p><code>Bad \\</code> Bad``</p>
   """
   
   Context-sensitive grammar isn't always easy to remember. Markdown's 
   work around is to have code snippets match in number.
   
   Here's a even more devious input involving image, once again in Markdown:
   
   """
   ![Alt Text\\]](URL)
   """
   
   Putting that code into Babelmark2 gives me many equally valid 
   interpretations, at least by human standard and by the spec, which 
   reads that "]" will be escaped by the backslash.
   
   """
   <p><img src="URL" alt="Alt Text]"></p>
   
   <p><img src="URL" alt="Alt Text\\]"></p>
   
   <p>[Alt Text\\]](URL)</p>
   
   <p>[Alt Text]](URL)</p>
   """
   
   Some interpreters treat the backslash as part of the verbatim text. 
   Some do not. Pandoc doesn't even escape the closing square bracket.
   
   There's still some consistency left regarding the escape syntax; All 
   interpreters escapes only *one* character with every escape character.
   
   """
   \\!![AltText](ImageURL)
   
   --> <img src="ImageURL" alt="AltText">
   """
   
#1 is simple, where the writer simply needs to remember adding an extra 
backslash if he's copying and pasting. 

#2, while appearing graceful to the writer, feels complicated and difficult. 
not to mention the inconsistency when the language is being implemented on 
other platforms.



End of Line (EOL) and Invisible Whitespace
--------------------------------------

The fenced block lexical tokens, like the aside block delimiters, currently 
requires an EOL token following these tokens immediately. If the user 
accidentally enters white space after these tokens, they don't get recognized 
anymore, and they will be confused as to why the document suddenly blows 
up in unexpected ways.

I should fix the parser so that, they still get recognized so long as there's 
only white space prior to the EOL, and after the delimiter tokens.



Fenced Block Force Indent
-------------------------

In aside and code blocks, I'm currently undecided as to whether I should 
enforce indentation rules in these blocks. 

"""
   ****
   Aside block
 ****
 Nested Aside block
 ****
   Aside block
   ****
"""

I think I should. Negative indentation is a very confusing way to specify 
document structure.



Kudos
=====

Despite the challenges, I feel that BakaBakaMark version 2 is better than 
version 1 in almost all aspects. I will name a select few strengths that 
that makes the language.


Aesthetics
----------

; Hyperlinks

  : The hyperlinks actually look like hyperlinks in free-flowing text of 
    a formal publication, save for the extra character before the opening 
    angle bracket. 
    
    """?<This URL>-[!<Image.jpg>-[With this display text]]""" 
    is a lot cleaner compared to 
    """?[[This URL || ![[Image.jpg || With so many brackets]]]]""".
    The reasons is that I've dropped all these double brackets and pipes 
    in favor of single square brackets, angle brackets, and hyphen.
    
    Angle brackets are the standard notation for delimiting URL in free 
    flowing text, as ?<RFC 1738> @ page 2 says. Adding a character, such 
    as "?" or "!" in front of "<" allows "<" to be used in other contexts
    without turning it into URL, while sacrificing little readability and 
    typing time. It's also context-free, meaning I don't have to be cautious 
    as to when I start parsing for URLs. 
    
    I made sure that """!< ?< #<""" are not used in any and all writing 
    contexts before using these prefix-characters, so writers are free to 
    emoji or ad-hoc ASCII math away in their paragraphs.
    
    Hyphen is often used for word-continuation. As such, I used a hyphen 
    immediately after the ">" to indicate that there's more information about 
    the hyperlink.
    
    After the hyphen, there's the extra information enclosed in a pair of 
    square brackets like an IEEE-style citation. This continuation can even 
    appear on the next line, so long as the next non-WS character is an 
    opening square bracket. As a result, I get a neatly delimited URL with 
    my own display text for that hyperlink.
    
    :{RFC 1738}: http://www.ietf.org/rfc/rfc1738.txt
    
    The other hyperlink syntax, """#[ID]""", is used to denote internal links 
    that points to locations within the same document. The hash mark looks 
    like an anchor, inspired by RFC 1738 document fragments and Twitter hash 
    tags. The square bracket looks like a footnote reference or extra 
    information. Putting them together, I get a great looking internal 
    link syntax that doesn't get used much elsewhere.
    
; Setext header

  : Version 2 of BakaBakaMark has SeTexT header support, which is a much 
    more visible way to represent a header in plain text, compared to a 
    single-line ATX-style header. 
    
    """
    === Title ===
    """
    
    Versus:
    
    """
    Title
    =====
    """
    
    The more lines a semantic construct takes, the more noticeable it will 
    be. A two-line title is by far more noticeable than a one-line title, 
    not to mention code reuse with the paragraph-parsing function.
    
; Improved Indentation-based Syntax

  : In BakaBakaMark version 2, paragraphs can continue only if all 
    non-whitespace token is sufficiently indented, based on the first 
    non-whitespace token that started the paragraph. Moreover, all leading 
    whitespace on a line is trimmed X characters, where X is the indentation 
    level of the paragraph.
    
    This new rule is a marked difference from the previous version, where 
    paragraphs were free to indent however it sees fit. The new rule enables 
    a much more compact, intuitive form of writing when it comes to nesting 
    block-level elements. Namely, list items can be specified one after 
    another without a blank line separating them:
    
    """
    - List item 1
    - List item 2
    - List item 3
    """
    
    That list looks much nicer, and more compact compared to the one 
    requiring blank lines:
    
    """
    - List item 1.
    List item 1 continued
    - Not list item 2.
    
    - List item 2.
    
    - List item 3.
    """


    
Power & Versatility
-------------------

; Whitespace control

  : The new indentation rule also lets one have direct control over 
    whitespace in paragraphs. This is very important for some languages 
    other than English, where there is no "white space" within a paragraph. 
    
    Most Latin-alphabet-based professional typesetting languages (professional 
    to the level of publishing magazines and books) to this date, such as 
    TeX, LaTeX, and HTML, treat new lines as a single whitespace. It's a 
    design decision that's used to aid automatic line-wrapping algorithms, 
    which in turn, lets the writers worry about presentation instead of 
    content. However, that very design decision will insert erraneous white
    space in manually line-wrapped Chinese and Japanese text, which is a 
    perfectly reasonable thing to expect of a writer working in plain text.
    
    """
    HTML:
    
    <p>
     中文中文中文中文中文中文
     中文中文中文中文中文中文
    </p>
    
    Mozilla Firefox 24:
    
    中文中文中文中文中文中文 中文中文中文中文中文中文
    """
    
    Meanwhile, by trimming excessive white space from every line in the 
    paragraph, the writer can control whether there should be a white space 
    or not by writing in this format:
    
    """
    Assume that underscores are leading white space, and the "@" sign 
    denotes extra space after the leading space.
   
    _This line starts on column 2. All text in the paragraph must
    _@start on column 2 or higher.
    _@This line will have leading white space, even if newlines are
    _@removed. This means that Chinese and Japanese text will see an
    _@awkward, but intentional white space between each character.
    """
    
    By default, the compiler treats newline as white space in the context 
    of a paragraph, which can be turned off as an option.
    
    Moreover, the forced indentation rule lets the writer input significant 
    white space into the URL of a hyperlink without resorting to the ugly
    percentage encoding scheme, which is by far more readable. The server is 
    still responsible for properly encoding the whitespace, however.
    
; Semantic Details

  : BakaBakaMark can specify the semantics of a document to the very 
    last detail, without interfering with the writing process.
    
    Specifically, my language can distinguish a list containing a list 
    item with two paragraphs, from a list that contains two list items, 
    where each item contains one paragraph. These two lists have different 
    semantics and BakaBakaMark is able to distinguish one from 
    another. Here's the code:
    
    """
    1. List item 1, paragraph 1.
    2. List item 2, paragraph 1.
    
    .
    
    * List item 1, paragraph 1
    
      List item 1, paragraph 2
    """
    
    Followed by the HTML rendering:
    
    1. List item 1, paragraph 1.
    2. List item 2, paragraph 1.
    
    .
    
    1. List item 1, paragraph 1
    
       List item 1, paragraph 2
      
    They all look perfectly natural, but one can easily spot, and reproduce 
    the subtle difference thanks to the list item markers' placement.
    
; Expressiveness

  : BakaBakaMark tables are probably the most powerful construct in any 
    lightweight markup language I have noticed:
  
    """
    || Col 1 Row 1
    || **Col 2 Row 1 is a bold paragraph.**
    |====
    || > Col 1 Row 2 starting with a blockquote
    
         This block quote contains two paragraphs.
         
       This is the comment about the blockquote.
       
    || - Col 2 Row 2 starts with a bullet list
       - Which has this item
       - and this item, totalling up to three.
       
       || This
       || is
       |====
       || a
       || two-by-two table after the bullet list, inside the last cell
          of the parent table.
    """
    
    While not as readable as a 2D ASCII table, like the one presented by 
    ?<PHP Markdown>, BakaBakaMark tables has the expressive power that can 
    rival HTML itself.
    
    :{PHP Markdown}: http://michelf.ca/projects/php-markdown/extra/#table
    
  : By placing one block-level token after another, I spend practically 
    no effort constructing a well-structured document without losing too 
    much readability. My block-level elements are free to contain any other 
    block-level elements as allowed by the HTML 4 and HTML 5.
    
  : Next, there's an aside block construct, which functions like the HTML
    """<div>""" or """<section>""" element, creating arbitrary block level 
    element that can be used to represent special sections of a document. 
    
  : Finally, there's a syntax that can specify the CSS class and ID of a 
    block level element. With some CSS templating, the aside block construct, 
    and brilliant web browsers such as Google Chrome, BakaBakaMark can 
    even display floating diagrams with text-wrapping like those found in 
    a magazine. 
    
    """
    . Figure 1
    .. left-text-wrap
    *****************
    !<Mr. X>-[Photoshoot of Mr. X]
    
    This is Mr. X attempting to break into a top-secret document safe, 
    and getting caught red-handed.
    
    :{Mr. X}: http://www.example.com/image.cgi?=id&20
    *****************
    
    This is some text wrapped around the diagram.
    """
    
    
    
    
Simplicity
----------

These ASCII art diagrams should explain the basic concept behind 
BakaBakaMark structuring, which is the only thing that didn't get 
changed from version 1.

"""
===============================
| Block Marker | Block 1      |
===============|              |
               | Block 2      |
               |              |
               | Block 3      |
               | ...          |
               ================
               
Block 1, 2, 3 are under the same containing block, such as a blockquote, 
as long as they are consistently indented to the same level.
               
If the next block marker is of the same time, join them into a bigger 
block as appropriate. E.g: Five consecutive bullet list item equates to 
a bullet list containing five list items:

""""
<ul_li>
<ul_li>
<ul_li>
<ul_li>
<ul_li>

------>

<ul>
 <li>
 <li>
 <li>
 <li>
 <li>
</ul>
""""
              
  =======================
  | Fenced Block Marker |
  =======================
  
  ===============================
  | Block Marker | Block 1      |
  ===============|              |
                 | Block 2      |
                 |              |
                 | Block 3      |
                 | ...          |
                 ================
               
  ===============================
  | Block Marker | Block 1      |
  ===============|              |
                 | Block 2      |
                 |              |
                 | Block 3      |
                 | ...          |
                 ================
                 
  ... and more blocks, so long as 
  it has sufficient indentation.
  
  =======================
  | Fenced Block Marker |
  =======================
  
===================================
| Line Marker || Rest of the line |
===================================
  
===================================
| Not Block Marker.               |
| Paragraph                       |
| Paragraph                       |
| Paragraph                       |
| Paragraph continues...          |
===================================
"""

It is a top-down, recursive descent grammar without any left-recursion. 
It is easy to understand as it is easy to parse.



Ending
======

Between Italic typeface conflict and syntax escaping, it looks like I need 
to introduce syntax escaping. I can't think of any other ASCII characters 
that look like a good fit for Italic typeface. 

Coming up next are the fenced blocks. I need to account for optional white 
space between the delimiter tokens and the EOL. I should also enforce 
indentation rules with these fenced blocks.

Syntax abuse, as well as code smells are going to be difficult. I don't 
think I will move to the semantic analysis and beyond so long as these 
issues are unresolved. I need to make sure my program is maintainable.

